# 1. **MLP에 Batch Normalization 적용하기**

이번 실습에서는 Mutlilayer Perceptron(MLP) 모델에 Batch Normalization이 추가되면 모델의 성능이 어떻게 변하는지 알아보도록 하겠습니다.

사용할 데이터셋은 Fashion MNIST 데이터셋입니다.

![img](https://cdn-api.elice.io/api-attachment/attachment/350ea97abc1543f4addbaf8257953da2/fashion_mnist-3.0.1.png)

## 지시사항

1. 기본적인 MLP 모델을 만드는 함수

    

   ```
   build_mlp_model
   ```

   을 완성하세요. Layer 구성은 다음과 같습니다.

   - `layers.Flatten`

   - ```
     layers.Dense
     ```

     - 노드 개수: `1024개`
     - 활성화 함수: `ReLU`

   - ```
     layers.Dense
     ```

     - 노드 개수: `256개`
     - 활성화 함수: `ReLU`

   - ```
     layers.Dense
     ```

     - 노드 개수: `10개`
     - 활성화 함수: `Softmax`

1. Batch Normalization이 추가된 MLP 모델을 만드는 함수

    

   ```
   build_bn_mlp_model
   ```

   을 완성하세요.

   - 한가지 주의할 점은 `Dense` Layer에서 **활성화 함수를 적용하지 않는다**는 점입니다. 일반적으로 Batch Normalization이 추가되면 Batch Normalization 결과에 활성화 함수를 적용하기 때문입니다. ([참고](https://gaussian37.github.io/dl-concept-order_of_regularization_term/))

   - `layers.Flatten`

   - ```
     layers.Dense
     ```

     - 노드 개수: `1024개`

   - `layers.BatchNormalization`

   - `layers.Activation("relu")`

   - ```
     layers.Dense
     ```

     - 노드 개수: `256개`

   - `layers.BatchNormalization`

   - `layers.Activation("relu")`

   - ```
     layers.Dense
     ```

     - 노드 개수: `10개`
     - 활성화 함수: `Softmax`



# 2. **Batch Normalization과 Dropout**

이번 실습에서는 CNN 모델에서 정규화(Regularization)를 적용하기 위해 사용하는 대표적인 두 장치인 Batch Normalization과 Dropout을 적용하여 모델을 만들어보도록 하겠습니다.

정규화가 실제로 효과가 있는지를 쉽게 알아보기 위해 **[개와 고양이 데이터셋](https://www.kaggle.com/c/dogs-vs-cats)** 에서 일부만을 가져와 학습 데이터셋의 개수를 의도적으로 줄이도록 하겠습니다.

![img](https://cdn-api.elice.io/api-attachment/attachment/ea11a2c22a1b4e0d846b9fca7a568531/woof_meow.jpg)

그리고 나서 Batch Normalization과 Dropout이 **적용되지 않은 모델과 적용된 모델**을 비교하여 성능이 어떻게 차이나는지 알아보도록 하겠습니다.

## 지시사항

이번 실습에서는 두 CNN 모델을 학습합니다. 코드를 완성하게 되면 **각각 학습에는 3분 정도**의 시간이 소요될 것이며, 따라서 **총 6분 정도**의 시간이 소요될 것입니다.

학습이 완료된 후에 기본 CNN과 Batch Normalization과 Dropout이 추가된 CNN 모델의 테스트 성능이 어떻게 차이나는지 확인해보세요.

지시사항에 따라 코드를 완성하세요.

1. 정규화가

    

   포함되지 않은

    

   CNN 모델을 만드는 함수

    

   ```
   build_cnn_model
   ```

   을 완성하세요. Layer 구성은 다음과 같습니다.

   - ```
     layers.Conv2D
     ```

     - 커널 개수: `16개`
     - 커널 크기: `(3, 3)`
     - padding: `"same"`
     - 활성화 함수: `ReLU`
     - `input_shape=img_size`

   - `layers.MaxPool2D`: 이미지 사이즈를 **2배**로 줄이세요.

   - ```
     layers.Conv2D
     ```

     - 커널 개수: `32개`
     - 커널 크기: `(3, 3)`
     - 활성화 함수: `ReLU`
     - padding: `"same"`

   - `layers.MaxPool2D`: 이미지 사이즈를 **2배**로 줄이세요.

   - ```
     layers.Conv2D
     ```

     - 커널 개수: `64개`
     - 커널 크기: `(3, 3)`
     - padding: `"same"`
     - 활성화 함수: `ReLU`

   - `layers.MaxPool2D`: 이미지 사이즈를 **2배**로 줄이세요.

   - `layers.GlobalAveragePooling2D`

   - ```
     layers.Dense
     ```

     - 노드 개수: `256개`
     - 활성화 함수: `ReLU`

   - ```
     layers.Dense
     ```

     - 노드 개수: `num_classes개`
     - 활성화 함수: `Softmax`

1. 정규화가

    

   포함된

    

   CNN 모델을 만드는 함수

    

   ```
   build_reg_cnn_model
   ```

   을 완성하세요. Layer 구성은 다음과 같습니다.

   - 한가지 주의할 점은 `Conv2D` Layer에서 **활성화 함수를 적용하지 않는다**는 점입니다. 일반적으로 Batch Normalization이 추가되면 Batch Normalization 결과에 활성화 함수를 적용하기 때문입니다. ([참고](https://gaussian37.github.io/dl-concept-order_of_regularization_term/))

   - ```
     layers.Conv2D
     ```

     - 커널 개수: `16개`
     - 커널 크기: `(3, 3)`
     - padding: `"same"`
     - `input_shape=img_size`

   - `layers.BatchNormalization`

   - `layers.Activation("relu")`

   - `layers.MaxPool2D`: 이미지 사이즈를 **2배**로 줄이세요.

   - ```
     layers.Conv2D
     ```

     - 커널 개수: `32개`
     - 커널 크기: `(3, 3)`
     - padding: `"same"`

   - `layers.BatchNormalization`

   - `layers.Activation("relu")`

   - `layers.MaxPool2D`: 이미지 사이즈를 **2배**로 줄이세요.

   - ```
     layers.Conv2D
     ```

     - 커널 개수: `64개`
     - 커널 크기: `(3, 3)`
     - padding: `"same"`

   - `layers.BatchNormalization`

   - `layers.Activation("relu")`

   - `layers.MaxPool2D`: 이미지 사이즈를 **2배**로 줄이세요.

   - `layers.GlobalAveragePooling2D`

   - ```
     layers.Dense
     ```

     - 노드 개수: `256개`
     - 활성화 함수: `ReLU`

   - ```
     layers.Dropout
     ```

     - rate: `0.5`

   - ```
     layers.Dense
     ```

     - 노드 개수: `num_classes개`
     - 활성화 함수: `Softmax`

1. ```
   run_model
   ```

    

   함수 내에서 모델 학습을 위한 optimizer, loss 함수, 평가 지표(metrics)를 설정하세요.

   - Optimizer:

      

     ```
     SGD
     ```

     - Learning Rate: `0.01`
     - `momentum=0.9`
     - `nesterov=True`

   - Loss 함수: `sparse_categorical_crossentropy`

   - 평가 지표: `Accuracy`



# 3. **Data Augmentation**

데이터 증강은 원본 데이터에 여러가지 전처리 기법을 사용하여 새로운 데이터를 만드는 기법입니다. 데이터셋에 있는 전체 데이터 개수가 적은 경우 이를 통해 데이터 개수를 늘려 모델의 학습 성능을 높이기 위해 사용합니다.

이번 실습에서는 이미지 데이터에 데이터 증강을 적용하는 방법을 Tensorflow를 통해 알아보도록 하겠습니다. Tensorflow에서는 데이터 증강 기법을 수행하기 위해 다양한 방식들을 제공합니다. 대표적인 방식은 다음과 같습니다.

1. ```
   tf.keras.layers
   ```

   에 구현된 클래스를 통해 기존 모델의 Layer와 함께 사용하는 방식

   ```
   augmentation_layer = tf.keras.Sequential([
       tf.keras.layers.RandomRotation(0.2),
       tf.keras.layers.RandomFlip(),
       # 기타 다른 전처리 Layer를 추가할 수 있습니다.
   )]
   Copy
   ```

1. ```
   tf.image
   ```

    

   또는

    

   ```
   tf.keras.preprocessing.image
   ```

    

   모듈의 함수를 사용하는 방식

   ```
   img = tf.image.random_crop(img, size=[5, 8])
   img = tf.keras.preprocessing.image.random_brightness(img, (0.2, 0.8))
   Copy
   ```

   - 다만 둘 중에선 `tf.image` 모듈에 더 많은 전처리 함수들이 구현되어 있습니다. 따라서 사용할 전처리 기법에 따라 원하는 쪽을 선택하면 됩니다.

1. ```
   tf.keras.preprocessing.image.ImageDataGenerator
   ```

   를 이용하는 방식

   - `ImageDataGenerator`는 전체 데이터셋을 제공하면 모델을 학습 또는 테스트할 때 필요한 부분의 데이터만 불러와주게 해주는 클래스입니다.
   - `ImageDataGenerator` 객체를 생성할 때 아래와 같이 다양한 옵션을 통해 불러오는 이미지에 전처리를 적용하여 데이터 증강의 효과를 줄 수 있습니다. 더 다양한 기법들은 [API 문서](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator?hl=ko)에서 확인해보세요.

   ```
   data_generator = tf.keras.preprocessing.image.ImageDataGenerator(rotation_range=40, height_shift_range=0.2, horizontal_flip=True)
   Copy
   ```

이번 실습에서는 셋 중에서 비교적 간단한 방식인 첫번째, `tf.keras.layers` 모듈을 통한 방식을 알아보도록 하겠습니다.

## 지시사항

실습에서는 아래 두 이미지에 전처리 작업을 수행할 것입니다.

![img](https://cdn-api.elice.io/api-attachment/attachment/b6b046d9f57b4b3f9a0d572619188a34/dog.jpg)

![img](https://cdn-api.elice.io/api-attachment/attachment/5385c09f8a4a4795820f288e74f54e25/cat.jpg)

지시사항에 따라 전처리를 수행하기 위한 Layer로 구성된 모델을 완성하세요.

1. 개 사진에 전처리를 수행하기 위한 모델인

    

   ```
   dog_augmentation
   ```

   을 완성하세요. 전처리를 위한 Layer 구성은 다음과 같습니다.

   - `layers.Resizing(IMG_SIZE, IMG_SIZE)`
   - `layers.Rescaling(1. / 255)`
   - `layers.RandomCrop(150, 200)`

1. 고양이 사진에 전처리를 수행하기 위한 모델인

    

   ```
   cat_augmentation
   ```

   을 완성하세요. 전처리를 위한 Layer 구성은 다음과 같습니다.

   - `layers.Resizing(IMG_SIZE, IMG_SIZE)`
   - `layers.Rescaling(1. / 255)`
   - `layers.RandomFlip()`
   - `layers.RandomRotation(0.5)`

참고로, 두 모델 모두 **resize와 rescale**을 위한 layer가 추가되어 있습니다. 이 둘은 일반적으로 딥러닝 모델을 학습할 때 모든 이미지의 크기를 동일하게 맞춰주고 정규화를 수행하기 위해 자주 사용합니다.



# 4. **ResNet-50 모델을 활용한 Transfer Learning**

![image](https://cdn-api.elice.io/api-attachment/attachment/67776f856ebe4987b886a4e29ff54df8/image.png)

어떤 모델을 처음부터 훈련시키기엔 시간이 오래 걸립니다.

그러나 훈련시킬 데이터셋이 기존의 방대한 데이터셋(ex. ImageNet)과 비슷한 성격의 데이터셋(ex. CIFAR-10)이라면, 사전에 방대한 데이터셋으로 훈련된 모델의 일부만 바꿔 적용해도 잘 작동할 것입니다.

이러한 모델 학습 방식을 **Transfer Learning**이라고 합니다.

이번 문제에서는 ImageNet으로 학습된 ResNet-50 모델을 불러온 후, 불러온 모델의 일부 Layer만 CIFAR-10으로 다시 학습시키는 작업인 Transfer Learning을 구현해볼 것입니다.

훈련시킬 데이터인 CIFAR-10은 data 폴더 안에 pickle 형태로 존재합니다. 이를 불러와 전처리하는 코드는 `preprocess.py` 에 구현되어 있습니다.

## 지시사항

1. `load_transfer_model()` 함수를 완성하세요. 먼저, 불러올 모델은 ImageNet으로 학습된 ResNet-50 모델입니다. 이 base 모델의 **weight가 학습되지 않도록** 설정하는 코드를 작성하세요.

1. ```
   transfer_model
   ```

   의 UpSampling2D Layer 뒤에

    

   base 모델을 연결

   하고, 이후엔

    

   다음 두 개의 Layer

   를 추가하세요.

   - `layers.GlobalAveragePooling2D`

   - ```
     layers.Dense
     ```

     - 노드 개수: `10개`
     - 활성화 함수: `Softmax`

1. 지시사항 2번에서 만든 모델을 훈련시키기 위해 optimizer와 손실 함수를 지정하는 코드를 작성하세요.

   - Optimizer :

      

     ```
     Adam
     ```

     - Learning Rate: `0.001`

   - 손실 함수 : `categorical_crossentropy`

   - 평가 지표 : `accuracy`

### 참고

지시사항 대로 코드를 작성하고 학습하게 되면 **굉장히 낮은** 테스트 정확도가 나오게 될 것입니다.

이는 플랫폼 상에서 Transfer Learning을 수행할 때 걸리는 시간이 매우 길어서 **데이터셋의 크기를 줄이고**, **epoch 수 또한 크게 줄였기 때문**입니다.

따라서 GPU를 활용할 수 있는 환경에서 전체 데이터셋을 사용하여 epochs 수를 늘리게 되면 유의미하게 성능이 나오는 것을 확인할 수 있습니다.

### Tips!

실행 및 채점 시간이 오래 걸릴 수 있으니 참고해주세요.